# ai-cyber-defender
ai-cyber-defender

# CyberDefender

## Опис

**CyberDefender** — це веб-додаток, розроблений для моніторингу та аналізу відвідувань користувачів на сайті.  
Додаток використовує технології **Django** та **Dash** для збору, обробки та візуалізації даних про відвідування, включаючи інформацію про:
- IP-адреси,
- геолокацію,
- браузери,
- пристрої користувачів.

### Основна мета проекту:
Надати адміністраторам сайтів інструменти для аналізу трафіку та покращення користувацького досвіду.

---

## Актуальні проблеми

Сайти часто стикаються з проблемами відстеження та аналізу відвідувань.  
**CyberDefender** вирішує ці проблеми, надаючи:
- зручний інтерфейс для збору даних,
- візуалізацію ключової інформації у вигляді графіків і діаграм.

---

## Цілі проекту

1. **Збір даних** про відвідування користувачів у реальному часі.
2. **Візуалізація даних** у вигляді графіків та діаграм для легкого аналізу.
3. **Детальний аналіз** геолокації, браузерів та пристроїв користувачів.

---

## Цільова аудиторія

Проект створено для:
- Адміністраторів веб-сайтів.
- Аналітиків даних.
- Маркетологів, які прагнуть розуміти поведінку користувачів на платформах.

---

## Структура репозиторію





```

CyberDefender/
│
├── CyberDefender/          # Основна папка з кодом проекту
│   ├── models.py           # Моделі бази даних
│   ├── views.py            # Представлення для обробки запитів
│   ├── urls.py             # URL-конфігурація
│   ├── forms.py            # Форми для обробки даних
│   ├── migrations/         # Міграції бази даних
│   └── plotly_app.py       # Dash-додаток для візуалізації даних
│
├── templates/              # Шаблони HTML
│   ├── base.html           # Базовий шаблон для всіх сторінок
│   ├── base_.html          # Альтернативний базовий шаблон
│   ├── buttons.html        # Сторінка з кнопками
│   ├── cards.html          # Сторінка з картками
│   ├── charts.html         # Сторінка з графіками
│   ├── home.html           # Головна сторінка
│   ├── index.html          # Інформаційна сторінка
│   ├── login.html          # Сторінка входу
│   ├── signup.html         # Сторінка реєстрації
│   ├── tables.html         # Сторінка з таблицями
│   ├── utilities-animation.html # Сторінка з анімаціями
│   ├── utilities-border.html    # Сторінка з бордюрами
│   ├── utilities-color.html     # Сторінка з кольорами
│   ├── utilities-other.html      # Інші утиліти
│   └── web_analytics.html        # Сторінка веб-аналітики
│
├── static/                 # Статичні файли (CSS, JS, зображення)
│   └── css/                # CSS-стилі
│
├── tests/                  # Тести
│   ├── test_models.py      # Тести для моделей
│   └── test_views.py       # Тести для представлень
│
├── manage.py               # Скрипт для управління проектом
├── requirements.txt        # Залежності проекту
└── README.md               # Документація проекту

```

## Архітектура веб-додатку CyberDefender

Архітектура веб-додатку **CyberDefender** побудована на основі принципів **MVC (Model-View-Controller)**, що дозволяє чітко розділити логіку бізнесу, представлення та управління даними. Це забезпечує легкість у підтримці, розширенні та тестуванні додатку.

Основні компоненти архітектури включають:

### 1. **Модель (Model)**
Моделі відповідають за управління даними та бізнес-логікою. У проекті **CyberDefender** моделі визначені у файлі `models.py` і включають:

- **Моделі бази даних**: Визначають структуру даних, які будуть зберігатися в базі даних. Це можуть бути моделі для користувачів, відвідувань, аналітики та інших об'єктів, що відслідковують інформацію про діяльність на вебсайті.
- **Міграції**: У папці `migrations/` зберігаються файли, які відповідають за зміни в структурі бази даних. Це дозволяє легко оновлювати схему бази даних, підтримуючи її актуальність під час розробки.

### 2. **Представлення (View)**
Представлення відповідає за обробку запитів користувачів і формування відповідей. У проекті **CyberDefender** представлення реалізовані у файлі `views.py` і включають:

- **Обробка запитів**: Логіка для обробки HTTP-запитів, отримання даних з моделей і передачі їх у шаблони для відображення користувачеві.
- **Взаємодія з формами**: Обробка даних, отриманих з форм (наприклад, форма реєстрації, форма входу), включаючи валідацію та збереження інформації в базі даних.

### 3. **Контролер (Controller)**
Контролер в архітектурі Django реалізується через **URL-конфігурацію**, що визначена у файлі `urls.py`. Він відповідає за:

- **Маршрутизацію запитів**: Визначає, яке представлення має обробити конкретний запит на основі URL-адреси.
- **Зв'язок між моделями та представленнями**: Контролер отримує дані з моделей і передає їх у представлення для формування відповіді.

### 4. **Шаблони (Templates)**
Шаблони відповідають за відображення даних користувачеві. У проекті **CyberDefender** шаблони зберігаються у папці `templates/` і включають:

- **Основні шаблони**: Базові шаблони, такі як `base.html`, які використовуються для створення інших сторінок.
- **Часткові шаблони**: Шаблони, які містять повторювані елементи інтерфейсу, такі як навігаційне меню, бічні панелі та нижні колонтитули, зберігаються у папці `templates/partials/`.

### 5. **Статичні файли (Static Files)**
Статичні файли, такі як **CSS**, **JavaScript** та **зображення**, зберігаються у папці `static/`. Вони використовуються для стилізації та покращення взаємодії з користувачем.

### 6. **Тестування (Testing)**
Тестування реалізовано у папці `tests/`, де зберігаються тести для моделей (`test_models.py`) та представлень (`test_views.py`). Це забезпечує перевірку коректності роботи додатку та його компонентів.

---

## Взаємодія компонентів

Користувач взаємодіє з додатком через веб-інтерфейс, надсилаючи запити (HTTP). Контролер (URL-конфігурація) обробляє ці запити, викликає відповідні представлення, які, у свою чергу, взаємодіють з моделями для отримання даних. Отримані дані передаються у шаблони для формування HTML-відповіді, яка повертається користувачеві.

Це забезпечує чітке розділення обов'язків між різними компонентами системи та дозволяє легко підтримувати і розширювати функціональність додатку.



## Моделі бази даних

Моделі бази даних у проекті **CyberDefender** визначають структуру даних, які зберігаються в базі даних, а також взаємозв'язки між цими даними. Вони реалізовані за допомогою **ORM (Object-Relational Mapping)** Django, що спрощує роботу з базою даних. Основні моделі включають:

### 1. **User (Користувач)**
Модель для зберігання інформації про користувачів, які можуть входити в систему та отримувати доступ до аналітики.

- **username**: Ім'я користувача (унікальне).
- **email**: Адреса електронної пошти (унікальна).
- **password**: Хешований пароль.
- **date_joined**: Дата реєстрації користувача.

### 2. **Visit (Відвідування)**
Модель для зберігання інформації про відвідування сайту, включаючи дані про користувача, IP-адресу, час відвідування та інформацію про пристрій.

- **user**: Зовнішній ключ до моделі `User` (може бути NULL, якщо відвідувач не зареєстрований).
- **ip_address**: IP-адреса відвідувача.
- **timestamp**: Дата та час відвідування.
- **user_agent**: Інформація про браузер та пристрій.
- **location**: Геолокація відвідувача (може бути представлена у вигляді рядка або окремих полів для широти та довготи).

### 3. **Analytics (Аналітика)**
Модель для зберігання аналітичних даних про відвідування конкретних сторінок, що дозволяє аналізувати поведінку користувачів на сайті.

- **visit**: Зовнішній ключ до моделі `Visit`.
- **page_url**: URL-адреса сторінки, яку відвідав користувач.
- **duration**: Час, проведений на сторінці (в секундах).

### 4. **Session (Сесія)**
Модель для зберігання інформації про сесії користувачів, що дозволяє відстежувати активність та тривалість сесій.

- **user**: Зовнішній ключ до моделі `User`.
- **session_key**: Унікальний ключ сесії.
- **created_at**: Дата та час створення сесії.
- **last_activity**: Дата та час останньої активності.

---

## Взаємозв'язки між моделями

- **User** та **Visit**: Один користувач може мати багато відвідувань, тому між цими моделями існує зв'язок "один-до-багатьох".
- **Visit** та **Analytics**: Одне відвідування може мати багато аналітичних записів, що також створює зв'язок "один-до-багатьох".
- **User** та **Session**: Один користувач може мати багато сесій, що формує зв'язок "один-до-багатьох".




# Рекомендації для поліпшення веб-додатку **CyberDefender**

Рекомендації для поліпшення веб-додатку **CyberDefender**, які можуть підвищити його ефективність, масштабованість та користувацький досвід:

### 1. **Покращення продуктивності**
- **Індексування бази даних:** Для зменшення часу виконання запитів, особливо для великих таблиць, можна додати індекси на найбільш запитувані поля (наприклад, `ip_address`, `user_agent`, `page_url` у моделях `Visit` та `Analytics`).
- **Кешування:** Використання кешування результатів для часто запитуваних даних (наприклад, аналіз відвідувань за певний період) допоможе зменшити навантаження на сервер та базу даних.
- **Асиметричне оброблення запитів:** Для великих обсягів даних (наприклад, аналітика) можна використовувати фонові задачі, щоб обробляти важкі операції (такі як генерування графіків або звітів) асинхронно за допомогою таких інструментів, як **Celery**.

### 2. **Безпека**
- **Шифрування чутливих даних:** Всі чутливі дані, такі як паролі користувачів, повинні зберігатися в зашифрованому вигляді за допомогою сильних хеш-функцій, таких як **bcrypt**.
- **Захист від атак CSRF:** Переконайтеся, що механізм захисту від атак типу **Cross-Site Request Forgery (CSRF)** налаштований і використовується для всіх форм, що надсилають запити до серверу.
- **Оновлення залежностей:** Регулярно оновлюйте залежності проекту, зокрема бібліотеки Django та Dash, щоб уникнути використання вразливих версій.
- **Опис моделей та API:** Використання **DRF** (Django REST Framework) для створення RESTful API для доступу до даних може забезпечити більшу гнучкість і безпеку при доступі до інформації.

### 3. **Покращення інтерфейсу користувача (UI/UX)**
- **Інтерактивні Dash-диаграми:** Оскільки в додатку використовується Dash для візуалізації даних, варто зробити графіки інтерактивними, даючи користувачам можливість фільтрувати або сортувати дані без необхідності перезавантажувати сторінку.
- **Мобільна адаптація:** Переконайтесь, що всі сторінки та елементи інтерфейсу мають адаптивний дизайн для коректної роботи на мобільних пристроях.
- **Зручний інтерфейс для фільтрації:** Для аналітики варто додати можливість фільтрувати дані по датах, геолокаціях, браузерах або типах пристроїв, що дозволить адміністраторам швидше отримувати потрібну інформацію.
- **Оптимізація швидкості завантаження:** Мінімізуйте використання великих зображень, оптимізуйте JavaScript та CSS файли, щоб зменшити час завантаження сторінок.

### 4. **Розширення функціональності**
- **Багатокористувацькі можливості:** Розгляньте можливість додавання ролей користувачів (наприклад, адміністратор, аналітик), щоб обмежити доступ до певних функцій або даних в залежності від ролі користувача.
- **Інтеграція з зовнішніми сервісами:** Можна додати можливість інтеграції з іншими сервісами аналітики або маркетингу (наприклад, Google Analytics або Facebook Pixel) для порівняння внутрішніх даних з зовнішніми.
- **Звіти та експорт даних:** Додайте можливість генерувати звіти на основі зібраних даних, а також експортувати їх у популярні формати, такі як CSV, Excel або PDF.
- **Моніторинг реального часу:** Впровадьте функціональність для відображення даних в реальному часі, наприклад, за допомогою WebSocket або AJAX, щоб адміністратори могли бачити нові відвідування без перезавантаження сторінки.

### 5. **Тестування та забезпечення якості**
- **Покриття тестами:** Розширте тестове покриття додатку, додаючи тести для бізнес-логіки, аналітики та валідації форм. Використовуйте **pytest** для написання більш зручних та ефективних тестів.
- **Автоматизація тестів:** Налаштуйте автоматизоване тестування за допомогою CI/CD (наприклад, використовуючи GitHub Actions або GitLab CI), щоб перевіряти якість коду під час кожного оновлення проекту.
- **Логування та моніторинг:** Додайте централізовану систему логування для моніторингу помилок, продуктивності та аномалій у додатку. Використання таких інструментів, як **Sentry** або **ELK Stack**, може допомогти швидко знаходити та виправляти проблеми.

### 6. **Масштабованість**
- **Використання Docker:** Розгортання додатку за допомогою **Docker** допоможе легко налаштовувати та запускати додаток у різних середовищах, а також спростить масштабування на різні сервери.
- **Розподілені системи:** Для масштабування збору та обробки даних у реальному часі можна впровадити розподілені системи обробки даних, наприклад, використовуючи **Apache Kafka** або **RabbitMQ** для обробки великих обсягів даних.

### 7. **Документація**
- **Документація для API:** Якщо проект включає REST API, важливо створити документацію для розробників (наприклад, за допомогою **Swagger** або **DRF-Spectacular**), щоб полегшити інтеграцію сторонніх розробників.
- **Документація для розробників:** Надати чітку інструкцію по налаштуванню та розгортанню додатку, а також пояснення про внутрішню структуру проекту, щоб нові розробники могли швидко адаптуватися.
- **Користувацька документація:** Створити прості та зрозумілі інструкції для користувачів (адміністраторів сайтів), щоб вони могли максимально ефективно використовувати всі функції додатку.

### 8. **Підтримка багатомовності**
- **Мультимовний інтерфейс:** Додайте підтримку кількох мов для користувачів з різних регіонів. Це можна зробити за допомогою вбудованого механізму переведення Django.

Загалом, поліпшення CyberDefender повинно фокусуватися на продуктивності, безпеці, зручності користування, розширенні функціональності та масштабованості, що дозволить зробити додаток більш зручним та ефективним для кінцевих користувачів.









### Як додати Apache Kafka, Apache Flink та ClickStream Processing до проекту CyberDefender та що це дасть?

Інтеграція **Apache Kafka**, **Apache Flink** і **ClickStream Processing** в проект CyberDefender дозволить вам збирати, обробляти та аналізувати дані відвідувань користувачів у реальному часі. Це допоможе вам здійснювати ефективну обробку потокових даних, створювати аналітику і виявляти аномалії або шаблони поведінки користувачів на вашому сайті.

### 1. **Що дасть інтеграція Apache Kafka, Apache Flink та ClickStream Processing?**

#### **Apache Kafka:**
   - **Надійний потік даних у реальному часі**: Kafka дозволяє здійснювати ефективний збір і передачу даних в реальному часі з сайту до системи обробки.
   - **Масштабованість і стійкість**: Kafka працює з великими потоками даних, має високу стійкість до відмов, що дає можливість без втрат обробляти мільйони подій відвідувань користувачів.
   - **Ізоляція компонентів**: Kafka дозволяє відокремити компоненти збору, обробки та зберігання даних, що полегшує масштабування і підтримку системи.

#### **Apache Flink:**
   - **Обробка потокових даних у реальному часі**: Flink дозволяє обробляти потоки даних на льоту, виконувати агрегацію, фільтрацію та аналіз даних у реальному часі, що критично для CyberDefender, коли потрібно відразу обробляти інформацію про відвідування.
   - **Віконні операції**: Flink підтримує обчислення на основі вікон (наприклад, аналіз кількості відвідувань за певний проміжок часу), що дозволяє ефективно здійснювати аналіз поведінки користувачів.
   - **Точність обробки та стійкість**: Flink забезпечує гарантовану обробку даних, навіть при відмовах системи.

#### **ClickStream Processing:**
   - **Аналіз послідовності дій користувача**: ClickStream Processing дозволяє відстежувати й аналізувати весь шлях користувача на сайті — від першого кліка до завершення сесії. Це дає глибше розуміння взаємодії користувачів із сайтом.
   - **Виявлення аномалій**: Система може автоматично виявляти незвичні або підозрілі дії, які можуть вказувати на шахрайство або інші проблеми.
   - **Персоналізація досвіду користувачів**: Відстеження кліків дозволяє створювати персоналізовані пропозиції для користувачів на основі їх поведінки.

### 2. **Як додати Apache Kafka, Apache Flink та ClickStream Processing до CyberDefender?**

#### а) **Налаштування Apache Kafka**

1. **Інсталяція та запуск Kafka:**
   - Встановіть Apache Kafka та Zookeeper, якщо це ще не зроблено.
     ```bash
     wget https://downloads.apache.org/kafka/2.8.0/kafka_2.13-2.8.0.tgz
     tar -xvzf kafka_2.13-2.8.0.tgz
     cd kafka_2.13-2.8.0
     bin/zookeeper-server-start.sh config/zookeeper.properties
     bin/kafka-server-start.sh config/server.properties
     ```

2. **Налаштування Kafka Producer (Python):**
   - Для збору даних про відвідування використовуйте Kafka producer:
     ```python
     from confluent_kafka import Producer
     import json

     def delivery_report(err, msg):
         if err is not None:
             print('Message delivery failed: {}'.format(err))
         else:
             print('Message delivered to {} [{}]'.format(msg.topic(), msg.partition()))

     conf = {
         'bootstrap.servers': 'localhost:9092',
         'client.id': 'python-producer',
     }

     producer = Producer(conf)

     def send_visit_data(visit_data):
         producer.produce('clickstream', key=visit_data['user_id'], value=json.dumps(visit_data), callback=delivery_report)
         producer.flush()
     ```

3. **Налаштування Kafka Consumer (Python):**
   - Для обробки даних з Kafka створіть consumer:
     ```python
     from confluent_kafka import Consumer, KafkaError
     import json

     def consume_visit_data():
         conf = {
             'bootstrap.servers': 'localhost:9092',
             'group.id': 'flink-consumer',
             'auto.offset.reset': 'earliest'
         }

         consumer = Consumer(conf)
         consumer.subscribe(['clickstream'])

         try:
             while True:
                 msg = consumer.poll(1.0)
                 if msg is None:
                     continue
                 if msg.error():
                     if msg.error().code() == KafkaError._PARTITION_EOF:
                         print('End of partition reached {0}/{1}'.format(msg.topic(), msg.partition()))
                     else:
                         print(msg.error())
                 else:
                     visit_data = json.loads(msg.value().decode('utf-8'))
                     print('Received visit data:', visit_data)
         finally:
             consumer.close()
     ```

#### б) **Налаштування Apache Flink для обробки даних з Kafka**

1. **Інсталяція Flink:**
   - Завантажте і налаштуйте Apache Flink:
     ```bash
     wget https://archive.apache.org/dist/flink/flink-1.16.0/apache-flink-1.16.0-bin-scala_2.12.tgz
     tar -xvzf apache-flink-1.16.0-bin-scala_2.12.tgz
     cd apache-flink-1.16.0
     ./bin/start-cluster.sh
     ```

2. **Інтеграція Flink з Kafka:**
   - Використовуйте Flink для підключення до Kafka та обробки даних:
     ```python
     from pyflink.datastream import StreamExecutionEnvironment
     from pyflink.connector.kafka import FlinkKafkaConsumer
     from pyflink.datastream import SimpleStringSchema
     from pyflink.common import WatermarkStrategy

     def flink_consumer():
         env = StreamExecutionEnvironment.get_execution_environment()

         properties = {
             'bootstrap.servers': 'localhost:9092',
             'group.id': 'flink-consumer',
         }

         consumer = FlinkKafkaConsumer(
             topics='clickstream',
             deserialization_schema=SimpleStringSchema(),
             properties=properties)

         stream = env.add_source(consumer)
         stream.print()  # Проста операція для відображення даних

         env.execute("Flink Kafka Consumer Job")
     ```

#### в) **Реалізація ClickStream Processing**

1. **Що таке ClickStream Processing?**
   - ClickStream Processing дозволяє відстежувати послідовність кліків користувачів на вашому сайті, що дає можливість виявляти шаблони поведінки, інтереси і аномалії.

2. **Обробка даних з ClickStream в Flink:**
   - Для обробки ClickStream даних можна використовувати Flink, який буде агрегувати і аналізувати поведінку користувачів на сайті.
   - Наприклад, ви можете аналізувати шляхи користувачів по сайту, визначати популярні сторінки або виявляти нетипову поведінку.

3. **Аналіз ClickStream даних в реальному часі:**
   - У Flink ви можете створити вікна для обчислення кількості відвідувань або тривалості сесії.
   - Наприклад, для виявлення аномалій, можна відслідковувати, коли користувачі занадто довго перебувають на певній сторінці або коли є багато відвідувань з одного IP-адреси.

4. **Додавання віконних обчислень у Flink:**
   ```python
   from pyflink.datastream import TimeCharacteristic
   from pyflink.common.time import Time

   def flink_window_processing():
       env = StreamExecutionEnvironment.get_execution_environment()
       env.set_stream_time_characteristic(TimeCharacteristic.EventTime)

       properties = {
           'bootstrap.servers': 'localhost:9092',
           'group.id': 'flink-clickstream-group',
       }

       consumer = FlinkKafkaConsumer(
           topics='clickstream',
           deserialization_schema=SimpleStringSchema(),
           properties=properties)

       stream = env.add_source(consumer)

       # Вікно для обробки даних за 5 хвилин
       stream.key_by(lambda x: x['user_id']) \
             .time_window(Time.minutes(5)) \
             .reduce(lambda x, y

: combine(x, y)) \
             .print()

       env.execute("Clickstream Analysis Job")
   ```

### 3. **Що дасть інтеграція цих компонентів?**

- **Реальний час:** Дані про відвідування сайту можуть бути оброблені і проаналізовані в реальному часі.
- **Масштабованість:** Kafka дозволяє обробляти великі обсяги даних без затримок.
- **Аналіз поведінки користувачів:** Ви зможете здійснювати глибокий аналіз шляху користувачів по сайту, виявляти аномалії та створювати персоналізовані рекомендації.
- **Надійність і стійкість:** За допомогою Kafka і Flink ваша система зможе забезпечити високу доступність і обробку даних без втрат.

Інтеграція цих технологій в проект CyberDefender дозволить створити потужну платформу для моніторингу і аналізу відвідувань користувачів у реальному часі з високим рівнем масштабованості та надійності.





